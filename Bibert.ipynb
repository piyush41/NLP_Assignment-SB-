{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/data1/home/piyushmishra/Setubandhan/Assign/quora_questions_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=[]\n",
    "input1=[]\n",
    "for i in range(df.shape[0]):\n",
    "    sent=df.iloc[i]['question1']+','+df.iloc[i]['question2']\n",
    "    n=[sent]\n",
    "    input.append(n)\n",
    "    n=[]\n",
    "    n.append(df.iloc[i]['question1'])\n",
    "    n.append(df.iloc[i]['question2'])\n",
    "    input1.append(n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "model = CrossEncoder('bert-base-uncased')\n",
    "scores = model.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28025922, 0.27901313, 0.2859418 , 0.32864764, 0.28998792,\n",
       "       0.2914392 , 0.31832182, 0.2922318 , 0.29578698, 0.30335608,\n",
       "       0.28303036, 0.2948082 , 0.29381227, 0.29399362, 0.27389133,\n",
       "       0.29365405, 0.3100008 , 0.29500666, 0.2917065 , 0.3064341 ,\n",
       "       0.28243995, 0.32079625, 0.31159604, 0.30469424, 0.31522754,\n",
       "       0.2736362 , 0.2916716 , 0.28447613, 0.2838558 , 0.32461882,\n",
       "       0.28899312, 0.3082673 , 0.29079553, 0.2893568 , 0.28666744,\n",
       "       0.281445  , 0.26749513, 0.30985275, 0.29844   , 0.27483433,\n",
       "       0.28224066, 0.3042697 , 0.29304802, 0.29276356, 0.28645065,\n",
       "       0.2705678 , 0.3148494 , 0.29723585, 0.27559936, 0.30821005,\n",
       "       0.2866774 , 0.29146475, 0.3097419 , 0.28784284, 0.30063662,\n",
       "       0.31042516, 0.30158174, 0.2830566 , 0.28010005, 0.30342752,\n",
       "       0.30581096, 0.297889  , 0.28724766, 0.304025  , 0.29289836,\n",
       "       0.29355112, 0.3081818 , 0.2859195 , 0.29404375, 0.28747794,\n",
       "       0.2880465 , 0.29136088, 0.2978531 , 0.29731116, 0.29114488,\n",
       "       0.28821218, 0.29148245, 0.301932  , 0.2968974 , 0.30383062,\n",
       "       0.27793616, 0.29013482, 0.32690972, 0.28000703, 0.28391987,\n",
       "       0.28596053, 0.2780542 , 0.28487384, 0.29626828, 0.28603673,\n",
       "       0.30171147, 0.32255378, 0.2979331 , 0.28740168, 0.28375643,\n",
       "       0.2985714 , 0.29778913, 0.3134185 , 0.28859195, 0.30348372],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1=list(df['question1'])\n",
    "sentences2=list(df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india? \t\t What is the step by step guide to invest in share market? \t\t Score: 0.9123\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond? \t\t What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back? \t\t Score: 0.6550\n",
      "How can I increase the speed of my internet connection while using a VPN? \t\t How can Internet speed be increased by hacking through DNS? \t\t Score: 0.5155\n",
      "Why am I mentally very lonely? How can I solve it? \t\t Find the remainder when [math]23^{24}[/math] is divided by 24,23? \t\t Score: 0.1041\n",
      "Which one dissolve in water quikly sugar, salt, methane and carbon di oxide? \t\t Which fish would survive in salt water? \t\t Score: 0.3253\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \t\t I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \t\t Score: 0.8375\n",
      "Should I buy tiago? \t\t What keeps childern active and far from phone and video games? \t\t Score: 0.0517\n",
      "How can I be a good geologist? \t\t What should I do to be a great geologist? \t\t Score: 0.9369\n",
      "When do you use シ instead of し? \t\t When do you use \"&\" instead of \"and\"? \t\t Score: 0.3227\n",
      "Motorola (company): Can I hack my Charter Motorolla DCX3400? \t\t How do I hack Motorola DCX3400 for free internet? \t\t Score: 0.7325\n",
      "Method to find separation of slits using fresnel biprism? \t\t What are some of the things technicians can tell about the durability and reliability of Laptops and its components? \t\t Score: -0.0599\n",
      "How do I read and find my YouTube comments? \t\t How can I see all my Youtube comments? \t\t Score: 0.8798\n",
      "What can make Physics easy to learn? \t\t How can you make physics easy to learn? \t\t Score: 0.9742\n",
      "What was your first sexual experience like? \t\t What was your first sexual experience? \t\t Score: 0.9718\n",
      "What are the laws to change your status from a student visa to a green card in the US, how do they compare to the immigration laws in Canada? \t\t What are the laws to change your status from a student visa to a green card in the US? How do they compare to the immigration laws in Japan? \t\t Score: 0.7922\n",
      "What would a Trump presidency mean for current international master’s students on an F1 visa? \t\t How will a Trump presidency affect the students presently in US or planning to study in US? \t\t Score: 0.6622\n",
      "What does manipulation mean? \t\t What does manipulation means? \t\t Score: 0.9894\n",
      "Why do girls want to be friends with the guy they reject? \t\t How do guys feel after rejecting a girl? \t\t Score: 0.5886\n",
      "Why are so many Quora users posting questions that are readily answered on Google? \t\t Why do people ask Quora questions which can be answered easily by Google? \t\t Score: 0.9152\n",
      "Which is the best digital marketing institution in banglore? \t\t Which is the best digital marketing institute in Pune? \t\t Score: 0.7099\n",
      "Why do rockets look white? \t\t Why are rockets and boosters painted white? \t\t Score: 0.8596\n",
      "What's causing someone to be jealous? \t\t What can I do to avoid being jealous of someone? \t\t Score: 0.7731\n",
      "What are the questions should not ask on Quora? \t\t Which question should I ask on Quora? \t\t Score: 0.6616\n",
      "How much is 30 kV in HP? \t\t Where can I find a conversion chart for CC to horsepower? \t\t Score: 0.4771\n",
      "What does it mean that every time I look at the clock the numbers are the same? \t\t How many times a day do a clock’s hands overlap? \t\t Score: 0.5055\n",
      "What are some tips on making it through the job interview process at Medicines? \t\t What are some tips on making it through the job interview process at Foundation Medicine? \t\t Score: 0.8291\n",
      "What is web application? \t\t What is the web application framework? \t\t Score: 0.7998\n",
      "Does society place too much importance on sports? \t\t How do sports contribute to the society? \t\t Score: 0.7725\n",
      "What is best way to make money online? \t\t What is best way to ask for money online? \t\t Score: 0.7380\n",
      "How should I prepare for CA final law? \t\t How one should know that he/she completely prepare for CA final exam? \t\t Score: 0.6755\n",
      "What's one thing you would like to do better? \t\t What's one thing you do despite knowing better? \t\t Score: 0.6411\n",
      "What are some special cares for someone with a nose that gets stuffy during the night? \t\t How can I keep my nose from getting stuffy at night? \t\t Score: 0.8096\n",
      "What Game of Thrones villain would be the most likely to give you mercy? \t\t What Game of Thrones villain would you most like to be at the mercy of? \t\t Score: 0.9396\n",
      "Does the United States government still blacklist (employment, etc.) some United States citizens because their political views? \t\t How is the average speed of gas molecules determined? \t\t Score: -0.0211\n",
      "What is the best travel website in spain? \t\t What is the best travel website? \t\t Score: 0.7633\n",
      "Why do some people think Obama will try to take their guns away? \t\t Has there been a gun control initiative to take away guns people already own? \t\t Score: 0.4955\n",
      "I'm a 19-year-old. How can I improve my skills or what should I do to become an entrepreneur in the next few years? \t\t I am a 19 year old guy. How can I become a billionaire in the next 10 years? \t\t Score: 0.6670\n",
      "When a girlfriend asks her boyfriend \"Why did you choose me? What makes you want to be with me?\", what should one reply to her? \t\t My girlfriend said that we should end this because she is confused about her feelings for me. I wished her well and disconnected. Should I call her and ask her if she wants to get back together? \t\t Score: 0.3130\n",
      "How do we prepare for UPSC? \t\t How do I prepare for civil service? \t\t Score: 0.5665\n",
      "What is the stall speed and AOA of an f-14 with wings fully swept back? \t\t Why did aircraft stop using variable-sweep wings, like those on an F-14? \t\t Score: 0.5887\n",
      "Why do Slavs squat? \t\t Will squats make my legs thicker? \t\t Score: 0.3631\n",
      "When can I expect my Cognizant confirmation mail? \t\t When can I expect Cognizant confirmation mail? \t\t Score: 0.9888\n",
      "Can I make 50,000 a month by day trading? \t\t Can I make 30,000 a month by day trading? \t\t Score: 0.9384\n",
      "Is being a good kid and not being a rebel worth it in the long run? \t\t Is being bored good for a kid? \t\t Score: 0.5094\n",
      "What universities does Rexnord recruit new grads from? What majors are they looking for? \t\t What universities does B&G Foods recruit new grads from? What majors are they looking for? \t\t Score: 0.6313\n",
      "What is the quickest way to increase Instagram followers? \t\t How can we increase our number of Instagram followers? \t\t Score: 0.8738\n",
      "How did Darth Vader fought Darth Maul in Star Wars Legends? \t\t Does Quora have a character limit for profile descriptions? \t\t Score: 0.0449\n",
      "What are the stages of breaking up between couple? I mean, what happens after the breaking up emotionally whether its a male or female? \t\t Who is affected more by a breakup, the boy or the girl? \t\t Score: 0.5721\n",
      "What are some examples of products that can be make from crude oil? \t\t What are some of the products made from crude oil? \t\t Score: 0.9165\n",
      "How do I make friends. \t\t How to make friends ? \t\t Score: 0.9733\n",
      "Is Career Launcher good for RBI Grade B preparation? \t\t How is career launcher online program for RBI Grade B? \t\t Score: 0.8014\n",
      "Will a Blu Ray play on a regular DVD player? If so, how? \t\t How can you play a Blu Ray DVD on a regular DVD player? \t\t Score: 0.9245\n",
      "Nd she is always sad? \t\t Aerodynamically what happens when propellor rotates? \t\t Score: 0.0312\n",
      "What is the best/most memorable thing you've ever eaten and why? \t\t What is the most delicious dish you've ever eaten and why? \t\t Score: 0.7865\n",
      "How GST affects the CAs and tax officers? \t\t Why can't I do my homework? \t\t Score: 0.0424\n",
      "How difficult is it get into RSI? \t\t Do you apply for programs like RSI when you're a rising senior? \t\t Score: 0.5925\n",
      "Who is israil friend? \t\t Is my boyfriend lying about his true feelings for his friend and is he secretly attracted to her? \t\t Score: 0.2307\n",
      "What are some good rap songs to dance to? \t\t What are some of the best rap songs? \t\t Score: 0.8243\n",
      "I was suddenly logged off Gmail. I can't remember my Gmail password and just realized the recovery email is no longer alive. What can I do? \t\t I can't remember my Gmail password or my recovery email. How can I recover my e-mail? \t\t Score: 0.8596\n",
      "What are the best ways to learn French? \t\t How do I learn french genders? \t\t Score: 0.7518\n",
      "How do I download content from a kickass torrent without registration? \t\t Is Kickass Torrents trustworthy? \t\t Score: 0.5285\n",
      "Is it normal to have a dark ring around the iris of my eye? \t\t What causes a dark ring around the iris? How should it be treated? \t\t Score: 0.8205\n",
      "How is the new Harry Potter book 'Harry Potter and the Cursed Child'? \t\t How bad is the new book by J.K Rowling? \t\t Score: 0.7011\n",
      "Why do I always get depressed? \t\t Why do I always get depressed in the evening? \t\t Score: 0.7706\n",
      "Where can I find a European family office database? \t\t Where do I find a U.S. family office database? \t\t Score: 0.7792\n",
      "What is Java programming? How To Learn Java Programming Language ? \t\t How do I learn a computer language like java? \t\t Score: 0.7826\n",
      "What is the best book ever made? \t\t What is the most important book you have ever read? \t\t Score: 0.7747\n",
      "Can we ever store energy produced in lightning? \t\t Is it possible to store the energy of lightning? \t\t Score: 0.9468\n",
      "What is your review of Performance Testing? \t\t What is performance testing? \t\t Score: 0.7811\n",
      "At what cost does so much privacy as in Germany come? What else is lost to gain so much privacy? \t\t Are there any people who genuinely enjoy salad with no dressing? \t\t Score: 0.0565\n",
      "What are the types of immunity? \t\t What are the different types of immunity in our body? \t\t Score: 0.9314\n",
      "What is a narcissistic personality disorder? \t\t What is narcissistic personality disorder? \t\t Score: 0.9937\n",
      "How I can speak English fluently? \t\t How can I learn to speak English fluently? \t\t Score: 0.9686\n",
      "How helpful is QuickBooks' auto data recovery support phone number to recover your corrupted data files? \t\t What is the quickbooks customer support phone number USA? \t\t Score: 0.6557\n",
      "Who is the richest gambler of all time and how can I reach his level? \t\t Who is the richest gambler of all time and how can I reach his level as a gambler? \t\t Score: 0.9936\n",
      "If I fire a bullet backward from an aircraft going faster than the bullet; will the bullet be going backwards? \t\t Do bullets travel faster than the speed of sound when shot from a gun? If not, is it possible? If they do, what gun and how much devastation occurs? \t\t Score: 0.5842\n",
      "How do I prevent breast cancer? \t\t Is breast cancer preventable? \t\t Score: 0.8440\n",
      "How do I log out of my Gmail account on my friend's phone? \t\t How can I know who logged in to my Gmail account? (by telling his IP address or device name)? \t\t Score: 0.5439\n",
      "How can I make money through the Internet? \t\t What are some different ways to make money online, excluding selling things? \t\t Score: 0.8030\n",
      "What is purpose of life? \t\t What's the purpose of life? What is life actually about? \t\t Score: 0.9120\n",
      "When will the BJP government strip all the Muslims and the Christians of the Indian citizenship and put them on boats like the Rohingya's of Burma? \t\t Why India does not apply the \"Burma-Rohingya model\" to deport illegal Bangladeshis? \t\t Score: 0.6130\n",
      "What is the right etiquette for wishing a Jehovah Witness happy birthday? \t\t How important is it to be the first person to wish someone a happy birthday? \t\t Score: 0.6633\n",
      "If someone wants to open a commercial FM radio station in any city of India, how much does it cost and what is the procedure? \t\t I want to make a travel commercial/clip video HD , For India and New Zealand. How much will it cost? \t\t Score: 0.4553\n",
      "Why do Swiss despise Asians? \t\t Why do technical employees despise sales people so much? \t\t Score: 0.3074\n",
      "What are some of the high salary income jobs in the field of biotechnology? \t\t What are some high paying jobs for a fresher with an M.Tech in biotechnology? \t\t Score: 0.8541\n",
      "How can I increase my height after 21 also? \t\t Can height increase after 25? \t\t Score: 0.7514\n",
      "What were the major effects of the cambodia earthquake, and how do these effects compare to the Kamchatca earthquakes in 1952? \t\t What were the major effects of the cambodia earthquake, and how do these effects compare to the Valparaiso earthquake in 1822? \t\t Score: 0.8948\n",
      "What is the difference between sincerity and fairness? \t\t What's the difference between honest and sincere? \t\t Score: 0.6834\n",
      "Which is the best gaming laptop under 60k INR? \t\t Which is the best gaming laptop under Rs 60000? \t\t Score: 0.7796\n",
      "What is your review of The Next Warrior: Proving Grounds - Part 9? \t\t What is your review of The Next Warrior: Proving Grounds - Part 5? \t\t Score: 0.9825\n",
      "What is the best reference book for physics class 11th? \t\t Which book should I choose for reference for physics and chemistry (class 11, CBSE board)? \t\t Score: 0.7618\n",
      "National Institute of Technology, Kurukshetra: How is the social life at NITK, Surathkal? \t\t National Institute of Technology Karnataka (NITK) , Surathkal: To the graduating batch: What lessons would you want to give to your juniors before you leave? \t\t Score: 0.6188\n",
      "What are some of the best romantic movies in English? \t\t What is the best romantic movie you have ever seen? \t\t Score: 0.8032\n",
      "What causes a nightmare? \t\t What causes nightmares that seem real? \t\t Score: 0.8398\n",
      "What is abstract expressionism in painting? \t\t What are some of the major influences of abstract expressionism? \t\t Score: 0.7118\n",
      "How does 3D printing work? \t\t How do 3D printing work? \t\t Score: 0.9966\n",
      "What was it like to attend Caltech with Jeremy Ehrhardt? \t\t Who are some notable folks who attended Caltech? \t\t Score: 0.6644\n",
      "Why did harry become a horcrux? \t\t What is a Horcrux? \t\t Score: 0.5902\n",
      "What are the best associate product manager (APM) programs that someone in their early 20s can join to learn product management and have a rewarding career in the company? \t\t What are the general requirement to become a Product Manager or a Program Manager in a product based software company? \t\t Score: 0.5708\n",
      "Why is the number for Skype at 1-855-425-3768 always busy? \t\t How could I get Skype to work on an android 4.1.1 phone? \t\t Score: 0.4791\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9123,  0.1147,  0.0963,  ...,  0.0262,  0.2122,  0.0382],\n",
       "        [-0.0059,  0.6550,  0.0243,  ...,  0.2108, -0.0634,  0.0108],\n",
       "        [ 0.0546, -0.1372,  0.5155,  ...,  0.0264,  0.0143,  0.0811],\n",
       "        ...,\n",
       "        [ 0.0303,  0.1430,  0.1108,  ...,  0.5902,  0.0454, -0.0441],\n",
       "        [ 0.1279, -0.1293, -0.0978,  ..., -0.0300,  0.5708,  0.0366],\n",
       "        [-0.0878, -0.0616,  0.1668,  ...,  0.0172,  0.0284,  0.4791]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#100*100 tensor where the diagonal elements are the similiarity between the sentences given in the csv \n",
    "cosine_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0744, -0.3269, -0.0529,  ..., -0.3176,  0.2509, -0.0072],\n",
      "        [ 0.1697, -0.1154,  0.0259,  ..., -0.2805,  0.1627,  0.1974]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0189, -0.0803, -0.1832,  ..., -0.1722,  0.4370, -0.0365],\n",
      "        [ 0.2055, -0.1955, -0.2088,  ..., -0.3583,  0.1617, -0.0256]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1238, -0.0029,  0.1179,  ..., -0.3461,  0.0177,  0.6082],\n",
      "        [ 0.3250, -0.0396, -0.1796,  ..., -0.4258,  0.0532,  0.5035]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.3157,  0.4559,  0.0919,  ..., -0.2604,  0.1364,  0.2113],\n",
      "        [ 0.1097, -0.1797,  0.4573,  ..., -0.5117,  0.0494,  0.5423]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0725,  0.5681,  0.1450,  ..., -0.5513,  0.2953,  0.2626],\n",
      "        [ 0.0901, -0.1247, -0.3498,  ..., -0.4124, -0.0048, -0.0435]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2602,  0.4011,  0.3074,  ...,  0.0228,  0.2105,  0.2219],\n",
      "        [ 0.1718,  0.3134,  0.4223,  ..., -0.1321,  0.1672,  0.0944]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1617, -0.2473, -0.0358,  ...,  0.0237,  0.0246,  0.2199],\n",
      "        [ 0.2225,  0.0601,  0.1470,  ..., -0.2463,  0.2978, -0.2337]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0640,  0.2973, -0.1738,  ..., -0.2968,  0.3323,  0.2084],\n",
      "        [ 0.1903,  0.3448, -0.2758,  ..., -0.1763,  0.2474,  0.0713]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0016, -0.2890, -0.3044,  ..., -0.2405,  0.1761, -0.0872],\n",
      "        [ 0.1315, -0.0627,  0.0352,  ..., -0.2594,  0.2270, -0.1085]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2488, -0.1739,  0.3682,  ..., -0.1239, -0.0418,  0.2631],\n",
      "        [ 0.3412, -0.0065,  0.2136,  ..., -0.4746,  0.0521,  0.1366]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.2385, -0.1196, -0.1910,  ..., -0.0007, -0.2197,  0.3174],\n",
      "        [ 0.1150,  0.2309,  0.0122,  ..., -0.1283, -0.1317,  0.2179]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 5.7810e-01,  3.6632e-04, -1.5603e-02,  ...,  1.8524e-02,\n",
      "          2.1244e-01, -3.3575e-02],\n",
      "        [ 5.1830e-01, -6.6596e-02,  2.9449e-01,  ...,  4.3831e-02,\n",
      "          1.0660e-03,  5.8356e-02]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1862, -0.0495,  0.1365,  ..., -0.1379, -0.0573,  0.4433],\n",
      "        [ 0.1613, -0.0088, -0.0769,  ..., -0.2003,  0.1473,  0.5345]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2935, -0.5336, -0.3172,  ..., -0.4112, -0.2783, -0.1581],\n",
      "        [ 0.1296, -0.5251, -0.3299,  ..., -0.4927, -0.1901, -0.2648]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1039, -0.0291,  0.1139,  ..., -0.3379,  0.1119,  0.3366],\n",
      "        [ 0.0845, -0.0940,  0.1117,  ..., -0.2939,  0.0992,  0.2777]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2285, -0.0015,  0.3596,  ..., -0.3135,  0.2471,  0.1588],\n",
      "        [ 0.2947, -0.0481,  0.3766,  ..., -0.4593,  0.0717, -0.1800]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.6738,  0.3782, -0.2186,  ..., -0.0819, -0.3592,  0.4401],\n",
      "        [ 0.6314,  0.3418, -0.0613,  ..., -0.2164, -0.3368,  0.4127]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1761,  0.0442, -0.2452,  ..., -0.1219, -0.1072,  0.1962],\n",
      "        [ 0.3054, -0.2172, -0.3552,  ..., -0.2977, -0.0411,  0.0853]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2480,  0.0666,  0.2270,  ..., -0.2589,  0.3090,  0.3632],\n",
      "        [ 0.2380,  0.2082,  0.0649,  ..., -0.3781,  0.2132,  0.5218]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0945, -0.4336, -0.0413,  ..., -0.4213,  0.6199, -0.1332],\n",
      "        [-0.1218, -0.4992,  0.0599,  ..., -0.4514,  0.6316, -0.0876]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2834,  0.4905, -0.2678,  ..., -0.2753,  0.1736,  0.1409],\n",
      "        [ 0.4751,  0.4607, -0.3315,  ..., -0.3549,  0.3467,  0.0587]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3082,  0.0317, -0.2130,  ..., -0.1800, -0.1817,  0.4436],\n",
      "        [ 0.1602,  0.0749, -0.3848,  ..., -0.1327, -0.1975,  0.3499]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 3.3907e-01,  9.2279e-02, -3.1396e-01,  ..., -2.8995e-02,\n",
      "         -1.2060e-02,  5.7074e-02],\n",
      "        [ 8.0241e-02, -4.5386e-02, -5.3704e-02,  ...,  1.4994e-01,\n",
      "          1.6329e-02, -1.7892e-05]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0532, -0.4287, -0.0267,  ..., -0.1379,  0.1665,  0.2525],\n",
      "        [-0.2578, -0.1443,  0.2558,  ..., -0.2845,  0.2690,  0.2579]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2816,  0.3519,  0.3713,  ...,  0.0722,  0.1701,  0.4327],\n",
      "        [ 0.4476,  0.3760,  0.2656,  ..., -0.3476,  0.2040,  0.2028]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1025, -0.0665,  0.1266,  ..., -0.2327,  0.0930, -0.0520],\n",
      "        [ 0.0590, -0.1235,  0.0781,  ..., -0.1476,  0.1235, -0.1264]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0819, -0.1251,  0.0212,  ..., -0.2013,  0.0334,  0.3438],\n",
      "        [-0.0141, -0.1555,  0.1964,  ..., -0.3017, -0.0746,  0.3147]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2447,  0.2718, -0.4300,  ..., -0.3475,  0.0866,  0.1148],\n",
      "        [ 0.2640,  0.0804, -0.1672,  ..., -0.5561,  0.1259,  0.0062]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3365, -0.0906, -0.1849,  ..., -0.3329,  0.2369,  0.2474],\n",
      "        [ 0.2667, -0.1263, -0.2057,  ..., -0.0746, -0.0406,  0.3800]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1790,  0.0583,  0.0711,  ...,  0.0094,  0.1087,  0.0795],\n",
      "        [-0.0453,  0.2678,  0.2500,  ..., -0.3910,  0.3143,  0.0326]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3776, -0.0318, -0.3184,  ..., -0.0320,  0.1408,  0.2219],\n",
      "        [ 0.3307,  0.1249, -0.3789,  ...,  0.1400, -0.2162,  0.1192]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1253,  0.2360,  0.1564,  ..., -0.0345, -0.0601,  0.0944],\n",
      "        [ 0.1150,  0.2122,  0.1533,  ..., -0.0978,  0.1751,  0.2718]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1787, -0.2702,  0.1231,  ..., -0.3456, -0.0365, -0.1802],\n",
      "        [ 0.1534, -0.1265, -0.0710,  ..., -0.3767, -0.1756,  0.1253]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3680,  0.1999, -0.0324,  ..., -0.5866, -0.2461,  0.1202],\n",
      "        [-0.0102, -0.1072, -0.0466,  ..., -0.3626, -0.1887,  0.3902]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.2337, -0.5993,  0.2028,  ..., -0.4141,  0.5417,  0.0695],\n",
      "        [-0.0074, -0.2925,  0.3321,  ..., -0.2071,  0.4734,  0.1807]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1837, -0.1476, -0.1305,  ..., -0.5611, -0.1364,  0.1263],\n",
      "        [ 0.2654, -0.2160,  0.0260,  ..., -0.5975, -0.2776,  0.2247]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1880,  0.2537,  0.3742,  ..., -0.4521,  0.1088, -0.0117],\n",
      "        [ 0.0322,  0.0472,  0.4152,  ..., -0.4286,  0.3987,  0.0782]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0259, -0.1159,  0.0103,  ..., -0.1833, -0.0955,  0.3808],\n",
      "        [ 0.1065, -0.3316,  0.1626,  ..., -0.0075, -0.2948,  0.0835]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2675, -0.1947, -0.0161,  ..., -0.0786,  0.3946,  0.0474],\n",
      "        [ 0.4366,  0.0584,  0.0503,  ...,  0.1146,  0.1803,  0.1043]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1080, -0.0274,  0.0752,  ..., -0.3261,  0.0612, -0.0140],\n",
      "        [ 0.1593,  0.0165, -0.0450,  ..., -0.2181,  0.0746, -0.0938]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4187,  0.3095, -0.3367,  ..., -0.7032, -0.0761, -0.1937],\n",
      "        [ 0.3510, -0.2114,  0.2093,  ..., -0.2696, -0.2077, -0.4125]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2454, -0.3158,  0.4801,  ..., -0.1647,  0.3046,  0.2156],\n",
      "        [ 0.3481, -0.3488,  0.3182,  ..., -0.2063,  0.2870,  0.2586]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3656,  0.1045,  0.3803,  ..., -0.4544,  0.2332, -0.0035],\n",
      "        [ 0.3408,  0.1143,  0.3692,  ..., -0.4690,  0.2268, -0.0103]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4871, -0.1810, -0.2048,  ...,  0.0384,  0.1299,  0.0190],\n",
      "        [ 0.4539, -0.1763,  0.0499,  ..., -0.2351, -0.0809,  0.0741]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3495,  0.0446,  0.3213,  ..., -0.0173,  0.2539,  0.0010],\n",
      "        [ 0.3377, -0.0404,  0.3965,  ..., -0.0954,  0.3451, -0.1803]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3555, -0.5036,  0.2580,  ..., -0.2431,  0.1441,  0.2586],\n",
      "        [ 0.7179, -0.2459,  0.4067,  ..., -0.2880,  0.3781,  0.0607]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2030, -0.4149, -0.2182,  ..., -0.0101,  0.1068,  0.0509],\n",
      "        [ 0.2847, -0.1754,  0.0355,  ..., -0.0271, -0.0786,  0.2595]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0079, -0.0902,  0.1190,  ..., -0.5425,  0.0372, -0.1187],\n",
      "        [-0.2037, -0.5410,  0.0687,  ..., -0.1761,  0.2465, -0.0840]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3376,  0.0366, -0.1867,  ..., -0.5058,  0.1136,  0.2702],\n",
      "        [ 0.3311,  0.0385, -0.2060,  ..., -0.5568,  0.1224, -0.2156]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1989,  0.0824, -0.1123,  ..., -0.2060,  0.2883, -0.0284],\n",
      "        [ 0.2904, -0.2705, -0.4056,  ...,  0.1260,  0.2324,  0.1131]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1727, -0.4119,  0.2480,  ..., -0.1638,  0.1476, -0.3115],\n",
      "        [ 0.0680, -0.6691,  0.2738,  ..., -0.2236,  0.1783, -0.0522]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3316, -0.1796,  0.3910,  ..., -0.2249,  0.4514, -0.0394],\n",
      "        [ 0.3223, -0.2167,  0.2058,  ..., -0.2708,  0.3474,  0.2859]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0906, -0.0259,  0.1648,  ..., -0.0669,  0.2289,  0.2321],\n",
      "        [-0.0043, -0.1979, -0.0605,  ..., -0.6308, -0.3160,  0.0605]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1889,  0.0733, -0.0238,  ...,  0.0221, -0.1256, -0.0694],\n",
      "        [ 0.1421,  0.0820, -0.1576,  ..., -0.1172,  0.0282,  0.2467]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3626,  0.0116,  0.1565,  ..., -0.2019,  0.0846,  0.1575],\n",
      "        [ 0.1931,  0.3966, -0.0470,  ..., -0.2681,  0.1156,  0.0365]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0632, -0.0288, -0.0706,  ..., -0.2501,  0.2278,  0.3068],\n",
      "        [ 0.3623, -0.2519,  0.3380,  ..., -0.1434, -0.0149,  0.0227]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.4034, -0.2733,  0.0231,  ..., -0.3076,  0.1323, -0.0464],\n",
      "        [ 0.3494,  0.0081,  0.0193,  ..., -0.1311,  0.2301,  0.3063]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2917, -0.1350,  0.2918,  ..., -0.3606, -0.1084, -0.0829],\n",
      "        [-0.0885, -0.1661,  0.3788,  ..., -0.2759, -0.0421, -0.2689]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0476,  0.0560,  0.2664,  ..., -0.1154, -0.2435,  0.1293],\n",
      "        [-0.0222,  0.1420,  0.1967,  ..., -0.0975, -0.2313,  0.3060]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0193,  0.3075, -0.1189,  ..., -0.1025,  0.1591,  0.1517],\n",
      "        [ 0.0268,  0.2648, -0.2175,  ..., -0.3204,  0.2355,  0.0881]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4664,  0.2583, -0.0191,  ..., -0.2277, -0.0290,  0.3089],\n",
      "        [ 0.5628, -0.1549,  0.1997,  ..., -0.1917,  0.0940, -0.0572]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2352, -0.1174, -0.2244,  ...,  0.0215, -0.1931,  0.0811],\n",
      "        [ 0.1378,  0.0969, -0.3444,  ..., -0.1360, -0.3094,  0.2988]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1124, -0.2528,  0.3712,  ...,  0.2608,  0.4591,  0.0440],\n",
      "        [ 0.1547, -0.4048,  0.2968,  ...,  0.0400, -0.0088,  0.0958]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0360,  0.2510, -0.0131,  ...,  0.0378,  0.0522, -0.1896],\n",
      "        [-0.3019,  0.0851,  0.1016,  ..., -0.1494,  0.2101, -0.2210]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0087, -0.1362,  0.1040,  ..., -0.4686,  0.1249,  0.2696],\n",
      "        [ 0.1033, -0.0195,  0.0648,  ..., -0.4377,  0.2401,  0.1410]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0461,  0.0175,  0.0291,  ..., -0.3185, -0.1368,  0.3266],\n",
      "        [ 0.0024,  0.2274,  0.0136,  ..., -0.4081, -0.0275,  0.4097]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0103, -0.1668,  0.1733,  ..., -0.1399,  0.4025, -0.0410],\n",
      "        [ 0.0893, -0.0787, -0.1041,  ..., -0.2081,  0.0932, -0.0771]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4764, -0.0593, -0.1042,  ..., -0.2492, -0.1454,  0.0647],\n",
      "        [ 0.2708, -0.1530, -0.2702,  ..., -0.1804, -0.1744,  0.2496]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1385, -0.1790, -0.3164,  ..., -0.1545,  0.0079,  0.1184],\n",
      "        [ 0.2947,  0.0475, -0.2118,  ..., -0.1233,  0.0061,  0.3342]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1158, -0.0439,  0.0815,  ..., -0.3529, -0.1288,  0.3304],\n",
      "        [ 0.1234, -0.1737, -0.1055,  ..., -0.3498,  0.1889,  0.1547]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2997, -0.0184, -0.0900,  ..., -0.1738, -0.2948,  0.1704],\n",
      "        [ 0.2775, -0.0738, -0.0391,  ..., -0.2352, -0.1753,  0.2442]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1366, -0.1635, -0.1243,  ..., -0.3744,  0.1293,  0.1765],\n",
      "        [ 0.2053, -0.1745, -0.1646,  ..., -0.3027,  0.1342,  0.1093]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1747,  0.1626,  0.0237,  ..., -0.3481,  0.2178, -0.0098],\n",
      "        [ 0.1735,  0.2288,  0.0923,  ..., -0.3876,  0.2292,  0.2475]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0858, -0.1939,  0.2850,  ..., -0.1173, -0.2697,  0.1906],\n",
      "        [ 0.1081, -0.2880,  0.2339,  ..., -0.1310,  0.1831,  0.1160]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.2143,  0.0293,  0.2497,  ..., -0.1099,  0.3375, -0.0071],\n",
      "        [-0.1380,  0.1372,  0.2682,  ..., -0.1247,  0.3010, -0.0182]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.0646, -0.1595,  0.1788,  ..., -0.2534,  0.0054,  0.2649],\n",
      "        [ 0.0643,  0.2067,  0.1590,  ..., -0.3541, -0.0051,  0.1070]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3282, -0.0779, -0.3632,  ..., -0.3625,  0.0450,  0.0513],\n",
      "        [-0.0266, -0.5035, -0.3871,  ..., -0.4122, -0.2235,  0.0474]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3774,  0.0218,  0.0838,  ..., -0.2192,  0.0814,  0.2176],\n",
      "        [ 0.1797,  0.0596,  0.2072,  ..., -0.2125,  0.0468,  0.4820]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4783,  0.1441, -0.2034,  ..., -0.4720,  0.3635,  0.2935],\n",
      "        [ 0.6145,  0.1548, -0.0646,  ..., -0.3572,  0.0644,  0.3272]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1736,  0.0728, -0.1391,  ..., -0.2031,  0.0024, -0.0196],\n",
      "        [ 0.4709,  0.1736,  0.1418,  ..., -0.0494,  0.0264,  0.4269]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1777, -0.0310, -0.0753,  ..., -0.5142,  0.0494, -0.1685],\n",
      "        [ 0.0889, -0.0432, -0.3299,  ..., -0.2837, -0.0876, -0.1621]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0513,  0.2625, -0.0297,  ...,  0.1120,  0.0704,  0.2543],\n",
      "        [ 0.0127,  0.1435, -0.0787,  ...,  0.3136, -0.0173,  0.5582]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2630, -0.0701, -0.0480,  ..., -0.1719,  0.4793,  0.1553],\n",
      "        [ 0.4948, -0.4289,  0.3826,  ..., -0.2573,  0.1436, -0.2031]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.3610,  0.3245, -0.3317,  ..., -0.3772,  0.1845, -0.1017],\n",
      "        [ 0.2839,  0.4775, -0.1326,  ..., -0.2925,  0.1609,  0.3081]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0372, -0.1189,  0.1800,  ..., -0.5302,  0.1446, -0.2037],\n",
      "        [ 0.3477, -0.0737,  0.2500,  ..., -0.2830,  0.0183, -0.1216]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2100,  0.0374,  0.2552,  ..., -0.4190,  0.2879, -0.0960],\n",
      "        [-0.0855, -0.3476,  0.2714,  ..., -0.1162, -0.1375,  0.0507]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1349,  0.0157,  0.0014,  ..., -0.1883,  0.2344, -0.1077],\n",
      "        [-0.1899, -0.1746,  0.0162,  ..., -0.1457,  0.2897,  0.0979]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0935, -0.0742, -0.3624,  ..., -0.0084, -0.0040,  0.2141],\n",
      "        [ 0.2624, -0.1595, -0.1612,  ...,  0.0079,  0.1550,  0.0858]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.4627, -0.3394,  0.4290,  ..., -0.2769,  0.3318,  0.0583],\n",
      "        [-0.2763, -0.2440,  0.5095,  ..., -0.3751,  0.4144, -0.0552]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1067, -0.8584,  0.1236,  ..., -0.0107, -0.2066, -0.3685],\n",
      "        [-0.1136, -0.8784,  0.1470,  ...,  0.0366, -0.2086, -0.3789]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.2488, -0.1611,  0.2757,  ..., -0.0663,  0.3985, -0.0631],\n",
      "        [-0.0595, -0.0500, -0.0723,  ...,  0.0786,  0.3529,  0.0862]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0292, -0.5243, -0.5039,  ..., -0.4824,  0.2514,  0.1077],\n",
      "        [ 0.1186, -0.1175, -0.0631,  ..., -0.2569,  0.1484, -0.0596]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.1475,  0.0080,  0.1931,  ..., -0.3660,  0.4102, -0.0055],\n",
      "        [ 0.0726, -0.3263, -0.0314,  ..., -0.3493,  0.4295, -0.0033]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.2362, -0.1706, -0.2427,  ..., -0.3670, -0.2081,  0.0261],\n",
      "        [ 0.2360,  0.0532,  0.0141,  ..., -0.3603, -0.1513, -0.0423]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1571,  0.1235, -0.1766,  ..., -0.1641,  0.0228,  0.3227],\n",
      "        [ 0.0828,  0.3112, -0.1213,  ..., -0.4055, -0.1371,  0.0305]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.4266,  0.1296, -0.0474,  ..., -0.5812, -0.1156,  0.3441],\n",
      "        [ 0.5002,  0.1131, -0.1359,  ..., -0.5505, -0.0246,  0.2162]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.6030, -0.2599, -0.0033,  ...,  0.0466,  0.0571, -0.0525],\n",
      "        [ 0.3200, -0.2213, -0.2638,  ..., -0.0764,  0.0632, -0.1717]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.0864, -0.0935,  0.0801,  ..., -0.0353,  0.1430, -0.0184],\n",
      "        [-0.0115, -0.0239, -0.1276,  ..., -0.2050, -0.0644,  0.2102]])\n",
      "Sentence embeddings:\n",
      "tensor([[-0.2625,  0.1981,  0.2891,  ..., -0.4647,  0.1266, -0.1890],\n",
      "        [ 0.0921,  0.1232,  0.0845,  ..., -0.3773, -0.0640,  0.1591]])\n",
      "Sentence embeddings:\n",
      "tensor([[ 0.1149,  0.1075,  0.2573,  ..., -0.1565,  0.2786,  0.1441],\n",
      "        [ 0.1351,  0.0841,  0.1634,  ..., -0.2513,  0.0762,  0.2123]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['What is the step by step guide to invest in share market in india? ', 'What is the step by step guide to invest in share market?']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sts-GBERT-bi-encoder')\n",
    "# model = AutoModel.from_pretrained('sts-GBERT-bi-encoder')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "score=[]\n",
    "# Tokenize sentences\n",
    "for i in range(len(input1)):\n",
    "    encoded_input = tokenizer(input1[i], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    print(\"Sentence embeddings:\")\n",
    "    print(sentence_embeddings)\n",
    "    cosine_scores = util.cos_sim(sentence_embeddings[0], sentence_embeddings[1])\n",
    "    score.append(cosine_scores.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9597508311271667,\n",
       " 0.8796856999397278,\n",
       " 0.8824726343154907,\n",
       " 0.5379066467285156,\n",
       " 0.6742489337921143,\n",
       " 0.8740227818489075,\n",
       " 0.5876770615577698,\n",
       " 0.8807622194290161,\n",
       " 0.7714179158210754,\n",
       " 0.828769862651825,\n",
       " 0.6193062663078308,\n",
       " 0.9015946984291077,\n",
       " 0.9573376178741455,\n",
       " 0.9582241177558899,\n",
       " 0.9895089864730835,\n",
       " 0.846177339553833,\n",
       " 0.9828141331672668,\n",
       " 0.8590032458305359,\n",
       " 0.9212809205055237,\n",
       " 0.9654505252838135,\n",
       " 0.866264283657074,\n",
       " 0.8337029218673706,\n",
       " 0.8180512189865112,\n",
       " 0.7029927968978882,\n",
       " 0.8206297159194946,\n",
       " 0.9730756878852844,\n",
       " 0.8953811526298523,\n",
       " 0.8434070944786072,\n",
       " 0.938932478427887,\n",
       " 0.6180237531661987,\n",
       " 0.8665691614151001,\n",
       " 0.7707244753837585,\n",
       " 0.8932883143424988,\n",
       " 0.6265673041343689,\n",
       " 0.9333825707435608,\n",
       " 0.8338425755500793,\n",
       " 0.9169002771377563,\n",
       " 0.758887529373169,\n",
       " 0.8264712691307068,\n",
       " 0.8252191543579102,\n",
       " 0.6708981394767761,\n",
       " 0.9704101085662842,\n",
       " 0.9971421360969543,\n",
       " 0.7745016813278198,\n",
       " 0.9316615462303162,\n",
       " 0.8912074565887451,\n",
       " 0.4633691906929016,\n",
       " 0.834494948387146,\n",
       " 0.8939831852912903,\n",
       " 0.8553338050842285,\n",
       " 0.8900420069694519,\n",
       " 0.861792266368866,\n",
       " 0.5353078842163086,\n",
       " 0.9045045375823975,\n",
       " 0.49157771468162537,\n",
       " 0.6683074235916138,\n",
       " 0.5941835045814514,\n",
       " 0.8700423240661621,\n",
       " 0.920775294303894,\n",
       " 0.8090139627456665,\n",
       " 0.8037342429161072,\n",
       " 0.7995879650115967,\n",
       " 0.7485929131507874,\n",
       " 0.9423975348472595,\n",
       " 0.8980710506439209,\n",
       " 0.8760543465614319,\n",
       " 0.8598538041114807,\n",
       " 0.8804243803024292,\n",
       " 0.8234108686447144,\n",
       " 0.6780192255973816,\n",
       " 0.9161668419837952,\n",
       " 0.9816786646842957,\n",
       " 0.9397027492523193,\n",
       " 0.8124310374259949,\n",
       " 0.986560583114624,\n",
       " 0.8424162268638611,\n",
       " 0.8602622747421265,\n",
       " 0.8698088526725769,\n",
       " 0.808688223361969,\n",
       " 0.8245658278465271,\n",
       " 0.8498360514640808,\n",
       " 0.7847517132759094,\n",
       " 0.7824420928955078,\n",
       " 0.8593812584877014,\n",
       " 0.8624384999275208,\n",
       " 0.7580746412277222,\n",
       " 0.9622439742088318,\n",
       " 0.9072336554527283,\n",
       " 0.9389568567276001,\n",
       " 0.9971368312835693,\n",
       " 0.8278418779373169,\n",
       " 0.8293493390083313,\n",
       " 0.8403042554855347,\n",
       " 0.8964707255363464,\n",
       " 0.8470928072929382,\n",
       " 0.9857521057128906,\n",
       " 0.713410496711731,\n",
       " 0.8667104244232178,\n",
       " 0.859014093875885,\n",
       " 0.7096236944198608]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
